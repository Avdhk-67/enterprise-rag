# Enterprise Document QA and Search Assistant - Project Summary

## ğŸ¯ Project Overview

This is a **production-ready Enterprise Document QA and Search Assistant** built with AWS, Generative AI, and advanced RAG (Retrieval-Augmented Generation) techniques. The system enables organizations to securely ingest, index, and query their document knowledge base with accurate, source-cited answers.

## ğŸ—ï¸ Architecture

### AWS Components Integration

1. **Amazon S3**
   - Document storage and ingestion
   - Organized bucket structure (raw-documents, processed, metadata)
   - Secure access via IAM policies

2. **AWS Bedrock**
   - **Claude 3 Sonnet**: Primary LLM for answer generation
   - **Claude 3 Haiku**: Fast generation for simple tasks
   - **Amazon Titan Embeddings**: Vector embeddings for semantic search

3. **Vector Database Options**
   - **Amazon OpenSearch Serverless**: Production vector store
   - **Pinecone**: Managed vector database alternative
   - **FAISS**: Local development option

4. **Optional AWS Services**
   - **Lambda**: Serverless document processing
   - **API Gateway**: REST API endpoints
   - **IAM**: Secure access control

### Core RAG Pipeline

```
Document Ingestion â†’ Processing â†’ Chunking â†’ Embedding â†’ Vector Store
                                                              â†“
User Query â†’ Query Rewriting â†’ Retrieval â†’ Generation â†’ Validation â†’ Response
```

## ğŸ“ Project Structure

```
enterprise-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/              # S3 document loading and processing
â”‚   â”‚   â”œâ”€â”€ s3_document_loader.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”œâ”€â”€ processing/             # Text cleaning and chunking
â”‚   â”‚   â”œâ”€â”€ text_cleaner.py
â”‚   â”‚   â””â”€â”€ chunker.py
â”‚   â”œâ”€â”€ embedding/              # Vector embeddings
â”‚   â”‚   â””â”€â”€ bedrock_embeddings.py
â”‚   â”œâ”€â”€ retrieval/              # Semantic search
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”œâ”€â”€ generation/             # LLM answer generation
â”‚   â”‚   â””â”€â”€ bedrock_llm.py
â”‚   â”œâ”€â”€ validation/             # Quality checks
â”‚   â”‚   â””â”€â”€ quality_checker.py
â”‚   â”œâ”€â”€ utils/                  # Configuration and AWS clients
â”‚   â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”‚   â””â”€â”€ aws_client.py
â”‚   â””â”€â”€ rag_pipeline.py         # Main pipeline orchestrator
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ aws_config.yaml         # AWS service configuration
â”‚   â””â”€â”€ rag_config.yaml         # RAG pipeline settings
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.py                # Project setup script
â”‚   â””â”€â”€ test_aws_connection.py  # AWS connection testing
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ usage_example.py        # Usage examples
â”œâ”€â”€ app.py                      # FastAPI application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Main documentation
â”œâ”€â”€ AWS_SETUP.md               # Detailed AWS setup guide
â””â”€â”€ PROJECT_SUMMARY.md         # This file
```

## ğŸ”‘ Key Features

### 1. Document Ingestion
- âœ… S3 integration for document storage
- âœ… Support for PDF, DOCX, TXT, MD formats
- âœ… Automatic document processing and chunking
- âœ… Metadata extraction and preservation

### 2. Advanced Chunking Strategies
- **Traditional**: Fixed-size chunks with overlap
- **Logical**: Semantic-aware chunking preserving context
- **Hybrid**: Combination of both approaches

### 3. Semantic Search
- Vector embeddings using AWS Bedrock Titan
- Multiple vector database backends
- Configurable similarity thresholds
- Top-K retrieval with relevance scoring

### 4. Answer Generation
- AWS Bedrock Claude 3 for high-quality responses
- Source citation and attribution
- Context-aware generation
- Configurable temperature and token limits

### 5. Quality Validation
- **Relevancy Check**: Verify retrieved documents are relevant
- **Grounding Check**: Ensure answers are based on context
- **Hallucination Detection**: Prevent fabricated information
- **Confidence Scoring**: Overall quality metrics

### 6. REST API
- FastAPI-based endpoints
- Document upload and ingestion
- Query interface
- Health checks and monitoring

## ğŸš€ Getting Started

### Prerequisites
- Python 3.9+
- AWS Account with appropriate permissions
- AWS CLI configured

### Quick Start

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure AWS**
   - Follow `AWS_SETUP.md` for detailed instructions
   - Set up S3 bucket, Bedrock access, and vector database
   - Configure `.env` file with credentials

3. **Test Connections**
   ```bash
   python scripts/test_aws_connection.py
   ```

4. **Run Setup**
   ```bash
   python scripts/setup.py
   ```

5. **Start Application**
   ```bash
   python app.py
   ```

6. **Ingest Documents**
   ```python
   from src.ingestion.pipeline import IngestionPipeline
   pipeline = IngestionPipeline()
   pipeline.ingest_from_s3(prefix="raw-documents/")
   ```

7. **Query Documents**
   ```python
   from src.rag_pipeline import RAGPipeline
   rag = RAGPipeline()
   result = rag.query("What is our refund policy?")
   ```

## ğŸ“Š API Endpoints

### Query Documents
```bash
POST /query
{
  "question": "What is the company policy?",
  "top_k": 5
}
```

### Ingest from S3
```bash
POST /ingest/s3?s3_key=raw-documents/example.pdf
```

### Upload and Ingest File
```bash
POST /ingest/file
Content-Type: multipart/form-data
file: [document file]
```

## ğŸ”’ Security Features

- IAM-based access control
- Encrypted S3 storage (SSE-S3 or SSE-KMS)
- Secure credential management via environment variables
- Document access logging
- Least privilege IAM policies

## ğŸ“ˆ Performance Considerations

- **Embedding Batch Size**: Configurable (default: 32)
- **Chunk Size**: Optimizable (default: 1000 tokens)
- **Retrieval Top-K**: Configurable (default: 5)
- **Similarity Threshold**: Filter low-relevance results (default: 0.7)

## ğŸ”§ Configuration

### AWS Configuration (`config/aws_config.yaml`)
- S3 bucket settings
- Bedrock model selection
- Vector database configuration
- Region and credentials

### RAG Configuration (`config/rag_config.yaml`)
- Chunking strategy and parameters
- Retrieval settings
- Generation parameters
- Validation thresholds

### Environment Variables (`.env`)
- AWS credentials
- Service endpoints
- Feature flags

## ğŸ§ª Testing

### Connection Testing
```bash
python scripts/test_aws_connection.py
```

### Usage Examples
```bash
python examples/usage_example.py
```

## ğŸ“š Documentation

- **README.md**: Main project documentation
- **AWS_SETUP.md**: Comprehensive AWS setup guide
- **spec.md**: Original RAG pipeline specification
- **PROJECT_SUMMARY.md**: This file

## ğŸ“ Based On

This project is inspired by and builds upon:
- [Complex RAG Guide](https://github.com/FareedKhan-dev/complex-RAG-guide)
- Advanced RAG techniques including:
  - Query rewriting
  - Chain-of-thought reasoning
  - Planning and execution
  - Multi-layer validation
  - RAGAS evaluation framework

## ğŸ”® Future Enhancements

- [ ] Query planning and execution system
- [ ] Chain-of-thought reasoning for complex queries
- [ ] RAGAS evaluation integration
- [ ] Multi-modal support (images, tables)
- [ ] Real-time document updates
- [ ] User feedback integration
- [ ] Advanced re-ranking strategies
- [ ] Conversational RAG with memory
- [ ] Pinecone integration
- [ ] Lambda-based async processing

## ğŸ’¡ Usage Tips

1. **Start with FAISS** for local development, then migrate to OpenSearch/Pinecone for production
2. **Test chunking strategies** to find optimal size for your documents
3. **Monitor confidence scores** to identify low-quality responses
4. **Use validation results** to improve retrieval and generation
5. **Enable S3 versioning** for document recovery
6. **Set up CloudTrail** for audit logging

## ğŸ†˜ Troubleshooting

See `AWS_SETUP.md` for common issues and solutions related to:
- AWS connection problems
- Bedrock model access
- Vector database setup
- IAM permissions

## ğŸ“„ License

Apache 2.0

---

**Built with â¤ï¸ using AWS, LangChain, and advanced RAG techniques**

